# Transcript Analyzer API

Analyze plain-text transcripts with an LLM and get back a concise summary plus a list of next actions.

This service follows clean/hexagonal architecture: clear ports/adapters, domain models, an application service, and an in-memory repository.

---

## âœ¨ Live API (Swagger UI)

**Production Docs:** [Swagger UI](https://sd-5035863-l.dattaweb.com/api8010/docs)

### How to use â€œTry it outâ€:

1. Open the Swagger URL above.
2. Expand `GET /v1/analyze`.
3. Click **Try it out**.
4. Enter a transcript (plain text).
5. Click **Execute** to see the response.

Use `GET /v1/analyses/{analysis_id}` to retrieve a previous result by ID.

> Note: The deployed URL is behind a reverse proxy with the `/api8010` prefix. Locally, use `http://127.0.0.1:8000/docs` (no prefix).

---

## ğŸ§± Project Layout

```
app/
â”œâ”€â”€ adapters/
â”‚   â””â”€â”€ openai.py            # OpenAI adapter implementing the LLM port
â”œâ”€â”€ api/
â”‚   â””â”€â”€ routes.py            # FastAPI routes (endpoints)
â”œâ”€â”€ domain/
â”‚   â””â”€â”€ models.py            # Domain entities (e.g., TranscriptAnalysis)
â”œâ”€â”€ repositories/
â”‚   â””â”€â”€ memory.py            # Thread-safe in-memory repository
â”œâ”€â”€ schemas/
â”‚   â””â”€â”€ api.py               # Pydantic request/response schemas
â”œâ”€â”€ services/
â”‚   â””â”€â”€ analyzer.py          # Application service orchestrating analysis flow
â”œâ”€â”€ ports/
â”‚   â””â”€â”€ llm.py               # LLM Port (interface)
â”œâ”€â”€ configurations.py        # Settings loader (OpenAI key/model from .env)
â”œâ”€â”€ dependencies.py          # DI helpers
â”œâ”€â”€ prompts.py               # System/User prompts
â””â”€â”€ main.py                  # FastAPI app factory & CORS setup
tests/
â””â”€â”€ ...                      # Pytest tests
```

---

## ğŸš€ Quickstart

### 1) Environment Setup

**Using Conda (recommended)**

```bash
conda create -n transcript-analyzer python=3.12
conda activate transcript-analyzer
```

**Using Poetry**

```bash
pip install poetry
poetry install
```

**Or with pip**

```bash
pip install -r requirements.txt
# or minimal:
pip install fastapi uvicorn pydantic pydantic-settings openai pytest pytest-cov
```

### 2) Environment Variables

Create a `.env` file at the root:

```env
OPENAI_API_KEY=sk-xxxx_your_key_here
OPENAI_MODEL=gpt-4o-mini-2024-07-18
```

### 3) Run the API

```bash
# with Poetry
poetry run uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload

# or plain
uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload
```

Open Swagger locally: [http://127.0.0.1:8000/docs](http://127.0.0.1:8000/docs)

---

## ğŸ”Œ Endpoints

All endpoints are prefixed with `/v1`.

### Analyze (GET)

```
GET /v1/analyze?transcript=...
```

**Response:**

```json
{
  "id": "uuid",
  "summary": "Short summary",
  "next_actions": ["Action 1", "Action 2"]
}
```

**400:** when transcript is empty

### Get by ID

```
GET /v1/analyses/{analysis_id}
```

- **200:** Returns the saved analysis
- **404:** Unknown `analysis_id`

### Batch Analyze (Async)

```
POST /v1/analyze/batch
```

**Body:**

```json
{
  "transcripts": [
    "First transcript...",
    "Second transcript..."
  ]
}
```

**200:** List of analyses  
**400:** When input list is empty or only blank items

---

## ğŸ§ª Testing

```bash
# Basic
pytest

# Verbose
pytest -v

# Coverage
pytest --cov
```

Make sure `.env` and virtual environment are active before running tests.

---

## ğŸ§  How it Works

- `ports/llm.py`: defines the interface.
- `adapters/openai.py`: implements OpenAI LLM adapter with structured output.
- `services/analyzer.py`: orchestrates validation, prompt building, calling LLM, formatting results.
- `repositories/memory.py`: stores results in a thread-safe map.
- `api/routes.py`: handles HTTP concerns.

Clean architecture ensures testability and separation of concerns.

---

## ğŸ§° cURL Examples

**Base URL (Local):** `http://127.0.0.1:8000`

### Analyze (GET)

```bash
curl -G "http://127.0.0.1:8000/v1/analyze"   --data-urlencode "transcript=We discussed migrating the database; Alice owns the rollout; ETA Friday."
```

### Analyze (POST)

```bash
curl -X POST "http://127.0.0.1:8000/v1/analyze"   -H "Content-Type: application/json"   -d '{"transcript": "We discussed migrating the database; Alice owns the rollout; ETA Friday."}'
```

### Get by ID

```bash
curl "http://127.0.0.1:8000/v1/analyses/<PASTE_ID_HERE>"
```

### Batch

```bash
curl -X POST "http://127.0.0.1:8000/v1/analyze/batch"   -H "Content-Type: application/json"   -d '{"transcripts": ["First transcript...", "Second transcript..."]}'
```

> For production, use: `https://sd-5035863-l.dattaweb.com/api8010` as base URL.

---

## ğŸ§¯ Troubleshooting

- **OpenAI adapter errors**  
  Ensure `.env` is correct and `app/configurations.py` is reading it.

- **Model not available**  
  Use a model accessible by your OpenAI account.

- **Empty transcript â†’ 400**  
  Send non-empty text in the query/body.

- **Reverse proxy issues**  
  Use correct base URL with prefix when behind reverse proxy (`/api8010`).

---

## ğŸ“ Notes

- In-memory storage only. Restarting clears data.
- Uses OpenAI structured outputs: `{ summary: str, next_actions: List[str] }`
- Keep an eye on OpenAI API usage (costs apply).

---

## ğŸ§­ License

**Internal project** â€” use per your organizationâ€™s policies.